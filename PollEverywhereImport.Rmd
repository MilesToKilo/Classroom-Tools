---
title: "PollEverywhere_Import"
author: "Miles Vaelncia"
date: "November 8th, 2024"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

### Load Packages  

```{r Load Packages, message = FALSE}
pack <- c("tidyverse",    # Main processing package
          "tinytex")      # Knit to pdf
package.check <- lapply(
  pack, # List of packages to load
  FUN = function(x) { # Making a function
    if (!require(x, character.only = TRUE)) { # If you can't find the package
      install.packages(x, dependencies = TRUE) # First install it
      library(x, character.only = TRUE) # Then load it
    }
  }
)
rm(list = ls()) # Clear
```

The listed packages are necessary for modifying the PollEverywhere exported gradebooks. I prefer using tidyverse functions to manipulate the data, and tinytex is needed to produce this rmarkdown file but isn't necessary for manipulating the gradebook.  

### Identify File Names For Batch Processing  

```{r Identify File Names For Batch Processing}
PE_List <- list.files("PollEverywhere", # Folder with Raw PE csv files
                      pattern = ".csv", full = TRUE) %>% 
  set_names(str_sub(., # Refere
                    16, -5)) %>% print() # Isolate name by character position
```

All of your raw csv files from PollEverywhere need to be stored within the same folder. Ideally, these are the only files in the folder, but you could leave non- ".csv" files within the folder, and not affect the code. Each of your files should be associated with the day of the PollEverywhere survey. My file pattern shows this by Week and day; i.e., Week 7, day 2 = W07D2. Depending on your file pattern, you can change the position to isolate your variable names.  

### Visualize Raw Imported Data  

```{r Visualize Raw Imported Data}
df <- read_csv("PollEverywhere/GradebookExample.csv", show_col_types = FALSE) %>% print()
df %>% separate_wider_delim(Email, "@", names = c("UCINet", NA) ) %>%
  transmute("Points Possible" = UCINet, 
            Points = (`Total answered` * 0.8) + (`Total points earned` * 0.2))
```

The gradebook loads with ease, but the headers are not exactly how we want to see them. As for the rows, the last row has summary data that isn't needed for your gradebook. These need to be considered to reduce the dataset to what we need as well as avoid incorrect data manipulations.  

### Batch Process Files  

```{r Batch Process Files}
PE_clean <- imap_dfr( # Run code separately on each file, then combine into 1 dataset
  PE_List, # List of file names to batch process
  ~ read_csv(.x, # Import each file in the list
             show_col_types = FALSE) %>% # Avoid printout for each upload
    add_column(Day = .y) %>% # Create column using names of each list element
    filter(!is.na(Rank)) %>% # filter out summary data at the bottom of each file
    separate_wider_delim(Email, # Separate the column with emails
                         "@", # Before the "@" is the UCINet ID
                         names = c("UCINet", NA)) %>% # Do not save the latter
    transmute( # Create new columns without keeping old columns
      "Points Possible" = as_factor(UCINet), # Rename for the upload file format
      FirstName = `First name`, LastName = `Last name`,
      Day = Day, # Keep this column
      Grade = (`Total answered` * 0.8) + (`Total points earned` * 0.2))) %>% # Ending <imap_dfr> combines into 1 dataset
  pivot_wider(names_from = Day, # Turn these column values into column names
              values_from = Grade) %>% # Assign these column values to the new column names
  print() # Check that this is what you expected
```

"imap_dfr" is a function that applies the following commands to each element within a list, and then combines all of the elements into a single dataframe. This is essential since all of the files need to be processed individually before preparing for export. First, we want to create a new column populated with the Day associated with the file. Second, we filter out the summary data by the rank column. All students are given a rank whereas a student may sign-in without an email, which can cause problems if used as a filter. Third, we only want to keep the columns needed for merging with your Canvas gradebook, which include: first name, last name, student email, and Day. If your raw gradebook has a column for student ID, change "SID" to match the column name and remove the "#" to uncomment that code. Then, we want to create a new column that gives full credit for students who answer at least 50% of the questions correctly. This concludes individually processing files, so we end the "imap_dfr" function to combine each element into 1 dataset. The last step is to separate their grades into columns according to the Day.  

### Export Gradebook  

```{r Export Gradebook}
SaveDate <- format(Sys.Date(), format = "%Y%b%d")
write_csv(PE_clean, # Dataset
          na = "", # Keep NAs as blank
          file.path("PE_E109", # Folder path
            str_c("E109_PE_Uploads_", # Change to your class information
                  SaveDate, ".csv"))) # File name
```

The final step is to export the dataset as a new csv file. First, auto-generate the date you make the new file. This helps with bookkeeping. If you want to save your exported gradebook in a specific folder, you can indicate its name within the quotations. If some students do not participate in the PollEverywhere survey, they will not be found in this csv file. I will have to see how this affects the entire gradebook when merging this file with Canvas, but I assume that Canvas will either give them zeroes or keep that slot empty.

```{r Final Code}
# List all CSV files in the specified folder
PE_List <- list.files("PE_E109", # Directory with raw CSV files
                      pattern = ".csv", full.names = TRUE) %>% 
  # Create named list of files with shortened names for reference
  set_names(str_sub(., start = 9, end = -5)) %>% 
  print()  # Print file names to verify structure

# Process each file and combine into one dataset
PE_clean <- imap_dfr(
  PE_List, # List of file names for batch processing
  ~ read_csv(.x, show_col_types = FALSE) %>%  # Load each file in list
    add_column(Day = .y) %>%  # Add Day column from file name for context
    filter(!is.na(Rank)) %>%  # Remove summary rows (usually marked by NA in Rank)
    
    # Separate Email column to extract UCINet ID only (before "@")
    separate_wider_delim(Email, "@", names = c("UCINet", NA)) %>%  
    
    # Standardize columns, including converting Points columns to double type
    mutate(
      FirstName = `First name`, LastName = `Last name`,  # Keep standardized name columns
      Day = Day,  # Retain Day for pivoting later
      across(matches("^Question_\\d+_Points$"), as.double)  # Convert Points columns to double
    ) %>% 
    
    # Reshape data to long format for question-related columns
    pivot_longer(
      cols = matches("^Question_\\d+_(Points|CheckIn)$"),  # Select columns with question data
      names_to = c("Question", ".value"),  # Create new columns "Question" and "value"
      names_pattern = "^(Question_\\d+)_(Points|CheckIn)$"  # Split names into Question and type
    ) %>% 
    select(UCINet, Question, Points, CheckIn, Day) %>%  # Retain only relevant columns
    
    # Calculate total checked-in points per UCINet ID for each day
    filter(!is.na(CheckIn)) %>%  # Only include rows where CheckIn is recorded
    group_by(UCINet, Day) %>%
    summarise(TotalPoints = sum(Points, na.rm = TRUE), .groups = "drop")  # Sum points and ungroup
) %>%
  
  # Reshape to wide format with days as columns and total points per day as values
  pivot_wider(
    names_from = Day,  # Use Day column names for new columns
    values_from = TotalPoints  # Populate with TotalPoints values
  ) %>% 
  arrange(UCINet) %>%  # Sort final data by UCINet ID for clarity
  print()  # Display final output

# Save processed data to a new CSV file with today's date
SaveDate <- format(Sys.Date(), format = "%Y%b%d")  # Format date as "YYYYMonDD"
write_csv(PE_clean, 
          na = "",  # Leave missing values blank
          file.path("PE_E109",  # Folder to save file
            str_c("E109_PE_Uploads_", SaveDate, ".csv")))  # Create file name with class info and date

```

